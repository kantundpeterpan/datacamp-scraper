{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my last two posts ([here](/building-a-datacamp-archive/) and [here](/webscraping-datacamp-courses-ii/)), I discussed my efforts to scrape the [DataCamp](http://datacamp.com/) website so that I could have a record of the courses I've taken. In this final post, I'm putting all the pieces together, discussing how the script works and showing what the final product looks like. \n",
    "\n",
    "There's a lot of code here, and I've frontloaded it into the first half of the post. You can choose your own adventure. If you're interested in how the script works, go to the next section. If you're interested in seeing what the script does, skip to the section \"In Action.\"\n",
    "\n",
    "Before I dive in, I want to say how excited I am about this project. A year ago, I could barely print `\"Hello world!\"`. But Thanks to sites like [DataCamp](http://datacamp.com/), communities like [The Carpentries](https://carpentries.org) and a heavy dose of [Stack Overflow](https://stackoverflow.com), I'm doing things like this. So if you're interested in coding or data science but think its something you could never do, think again. Keep a growth mindset, and dive right in.\n",
    "\n",
    "# How It Works\n",
    "\n",
    "Here's how the script works. The user passes the link of the course they want to `get_whole_course()`. This function then uses `get_course_outline()` to get a list of the chapters and lessons in each course and `make_chapter_notes()` to create a text file for each chapter and downloads a PDF of the chapter slides. It then creates a text file with a table of contents for each course. This allows for easy navegation of the course once all the text files are in my notes system (I use [nvALT](http://brettterpstra.com/projects/nvalt/) and [The Archive](http://zettelkasten.de)) Everything is organized using unqiue, 14-digit \"z numbers,\" which are assigned to each course and chapter.\n",
    "\n",
    "Here are the libraries I used, with a brief explanation of the role each one plays: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\t\t\t\t\t#For parsing the HTML\n",
    "from collections import OrderedDict\t\t\t\t#For storing chapter and lesson info\n",
    "from subprocess import Popen, PIPE, STDOUT\t\t#For accessing pandoc\n",
    "from urllib.request import urlopen, urlretrieve\t#For fetching the webpage, downloading PDF of slides\n",
    "import json\t\t\t\t\t\t\t\t\t\t#For dealing with website data that comes in JSON\n",
    "import pandas as pd\t\t\t\t\t\t\t\t#For create Zettelkasten-style filenames\n",
    "import re\t\t\t\t\t\t\t\t\t\t#For regex parsing of `sct`\n",
    "import subprocess\t\t\t\t\t\t\t\t#For accessing pandoc\n",
    "import pprint\t\t\t\t\t\t\t\t\t#For troubleshooting, looking through webpages, dictionaries, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's all the code you need to capture an entire course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_whole_course(link, return_z=False):\n",
    "\t'''Receives course URL from user. Gets ordered dict of chapters/lessons. \n",
    "\tCreates list of unique z_numbers, one for each chapter. \n",
    "\tCreates txt file for each chapter, fills each file with lesson content.\n",
    "\tGets course name. Creates table of contents.\n",
    "\tFeeds to: get_course_outline(), make_z_number(), make_chapter_notes(), \n",
    "\tget_course_title(), create_table_of_contents()'''\n",
    "\tcourse_dictionary = get_course_outline(link)\n",
    "\tz_list = make_z_number(len(course_dictionary.items())+1)\n",
    "\tfor chapter, lesson in course_dictionary.items():\n",
    "\t\tz_index = list(course_dictionary.keys()).index(chapter)\n",
    "\t\tfilename = z_list[z_index] + ' ' + chapter + '.txt'\n",
    "\t\tchapter_link = [lesson][0][1][1] \n",
    "\t\tmake_chapter_notes(filename, chapter_link)\n",
    "\tcourse_name = get_course_title(link)\n",
    "\tcreate_table_of_contents(course_dictionary, course_name, z_list)\n",
    "\tif return_z == True:\n",
    "\t\treturn z_list[-1]\n",
    "\n",
    "def get_course_outline(link):\n",
    "\t'''Receives link to course landing page from get_whole_course(). \n",
    "\tReturns ordered dict of chapters with lessons.'''\n",
    "\thtml = urlopen(link)\n",
    "\tsoup = BeautifulSoup(html, 'lxml')\n",
    "\tlesson_outline = soup.find_all(['h4', 'li'])\n",
    "\tchapters = OrderedDict()   # {chapter: [(lesson_name, lesson_link), ...], ...}\n",
    "\tfor item in lesson_outline:\n",
    "\t\tattributes = item.attrs\n",
    "\t\ttry:\n",
    "\t\t\tclass_type = attributes['class'][0]\n",
    "\t\t\tif class_type == 'chapter__title':\n",
    "\t\t\t\tchapter = item.text.strip()\n",
    "\t\t\t\tchapters[chapter] = []\n",
    "\t\t\tif class_type == 'chapter__exercise':\n",
    "\t\t\t\tlesson_name = item.find('h5').text\n",
    "\t\t\t\tlesson_link = item.find('a').attrs['href']\n",
    "\t\t\t\tchapters[chapter].append((lesson_name, lesson_link))\n",
    "\t\texcept KeyError:\n",
    "\t\t\tpass\n",
    "\treturn(chapters)\n",
    "\n",
    "def make_z_number(num):\n",
    "\t'''Takes int and returns a list of unique, 14-digit numbers. Only goes to 99.'''\n",
    "\tassert num < 100, 'Enter an int that is less than 100. Max list size is 99.'\n",
    "\tstring_list = []\n",
    "\tz_index = 0\n",
    "\tfor x in range(num):\n",
    "\t\tz_string = pd.to_datetime('now').strftime('%Y%m%d%H%S') #Did seconds instead of minutes to avoid repeats\n",
    "\t\tz_string = z_string + '{0:0>2}'.format(z_index)\n",
    "\t\tstring_list.append(z_string)\n",
    "\t\tz_index += 1\n",
    "\treturn string_list\n",
    "\n",
    "def make_chapter_notes(filename, link):\n",
    "\t'''Receives filename and lesson link from get_whole_course().\n",
    "\t(Note that a link from any lesson in a chapter will work. \n",
    "    That is, any lesson link has all the information for the chapter.)\n",
    "\tCycles through all lessons in chapter, converting each lesson and sub-exercise from HTML to Markdown.\n",
    "\tPrints all chapter content into text file.\n",
    "\tFeeds to: get_lesson_json(), NormalExercise_print(), BulletExercise_print(), \n",
    "\tMultipleChoiceExercise_print(), download_chapter_slides()'''\n",
    "\tlesson_json = get_lesson_json(link)\n",
    "\tfor item in lesson_json['exercises']['all']:\n",
    "\t\tif item['type'] == 'VideoExercise':\n",
    "\t\t\tpass\n",
    "\t\telif item['type'] == 'NormalExercise':\n",
    "\t\t\tNormalExercise_print(item, filename)\n",
    "\t\telif item['type'] == 'BulletExercise':\n",
    "\t\t\tBulletExercise_print(item, filename)\n",
    "\t\telif item['type'] == 'MultipleChoiceExercise':\n",
    "\t\t\tMultipleChoiceExercise_print(item, filename)\n",
    "\tdownload_chapter_slides(lesson_json, filename.strip('.txt'))\n",
    "\n",
    "def get_course_title(link):\n",
    "\thtml = urlopen(link)\n",
    "\tsoup = BeautifulSoup(html, 'lxml')\n",
    "\treturn soup.title.text\n",
    "\n",
    "def create_table_of_contents(dictionary, course_name, z_list):\n",
    "\t'''Receives course dictionary, course name, and list of unique z_numbers from get_whole_course().\n",
    "    Creates text file with contents of course, formatted in Markdown, with wiki-style links to each chapter.'''    \n",
    "\tfilename = z_list[-1] + ' ' + course_name + '.txt'\n",
    "\twith open(filename, 'a') as f:\n",
    "\t\tfor chapter, lessons in dictionary.items():\n",
    "\t\t\tz_index = list(dictionary.keys()).index(chapter)\n",
    "\t\t\tprint('\\n# ', '[[' + z_list[z_index] + ']]', chapter, '\\n', file=f)\n",
    "\t\t\tfor lesson_name, lesson_link in lessons:\n",
    "\t\t\t\tprint(\"   *\", lesson_name, file=f)\n",
    "\n",
    "def get_lesson_json(link):\n",
    "\t'''Receives lesson link from make_chapter_notes() and returns \n",
    "\tthe dictionary that holds all the information for the lesson's parent chapter.'''\n",
    "\thtml = urlopen(link)\n",
    "\tsoup = BeautifulSoup(html, 'lxml')\n",
    "\tstring = soup.find_all('script')[3].string\n",
    "\tjson_text = string.strip('window.PRELOADED_STATE=')[:-1]\n",
    "\tlesson_json = json.loads(json_text)\n",
    "\treturn lesson_json\n",
    "                \n",
    "def NormalExercise_print(json, f):\n",
    "\t'''Works with make_chapter_notes. Parses NormalExercise type lessons and prints them in \n",
    "\tmarkdown to file.\n",
    "\tFeeds to: convert_2_md(), get_success_msg().'''\n",
    "\twith open(f, 'a') as f:\n",
    "\t\tprint('#', json['title'], '\\n', file=f)\n",
    "\t\tprint('## Exercise\\n', file=f)\n",
    "\t\tprint(convert_2_md(json['assignment']), file=f)\n",
    "\t\tprint('## Instructions\\n', file=f)\n",
    "\t\tprint(convert_2_md(json['instructions'][:-2]), file=f)\n",
    "\t\tprint('## Code\\n', file=f)\n",
    "\t\tprint('```\\n' + convert_2_md(json['sample_code']).replace('\\\\', ''),'\\n```\\n', file=f)\n",
    "\t\tprint('```\\n' + convert_2_md(json['solution']).replace('\\\\', ''),'\\n```\\n', file=f)\n",
    "\t\tprint(get_success_msg(json['sct']) + '\\n', file=f)\n",
    "\n",
    "def BulletExercise_print(json, f):\n",
    "\t'''Works with make_chapter_notes. Parses BulletExercises type lessons and prints them in \n",
    "\tmarkdown to file.\n",
    "\tFeeds to: convert_2_md(), get_success_msg().'''\n",
    "\twith open(f, 'a') as f:\n",
    "\t\tprint('# ' + json['title'], '\\n', file=f)\n",
    "\t\tprint('## Exercise\\n', file=f)\n",
    "\t\tprint(convert_2_md(json['assignment']), file=f)\n",
    "\t\tprint('## Instructions & Code \\n', file=f)  \n",
    "\t\tfor item in json['subexercises']:\n",
    "\t\t\tprint(convert_2_md(item['instructions']), file=f)\n",
    "\t\t\tprint('```\\n' + item['sample_code'] + '\\n```\\n', file=f)\n",
    "\t\t\tprint('```\\n' + item['solution'] + '\\n```', file=f)\n",
    "\t\t\tprint(get_success_msg(item['sct']) + '\\n', file=f)\n",
    "\n",
    "def MultipleChoiceExercise_print(json, f):\n",
    "\t'''Works with make_chapter_notes. Parses MultipleChoice type lessons and prints them in \n",
    "\tmarkdown to file.\n",
    "\tFeeds to: convert_2_md(), get_correct_mc(), get_success_msg().'''\n",
    "\twith open(f, 'a') as f:\n",
    "\t\tprint('# ' + json['title'], '\\n', file=f)\n",
    "\t\tprint('## Exercise\\n', file=f)\n",
    "\t\tprint(convert_2_md(json['assignment']), file=f)\n",
    "\t\tprint(\"## Choices\\n\", file=f)\n",
    "\t\tfor choice in json['instructions']:\n",
    "\t\t\tprint('* ' + choice, file=f)\n",
    "\t\tprint('\\n**Correct answer: ' + get_correct_mc(json['sct']) + '**\\n', file=f)\n",
    "\t\tprint(get_success_msg(json['sct']) + '\\n', file=f)\n",
    "\n",
    "def convert_2_md(string):\n",
    "\t'''Receives a string of HTML and use Pandoc to return string in Markdown.'''\n",
    "\tp = Popen(['pandoc', '-f', 'html', '-t', 'markdown', '--wrap=preserve'], stdout=PIPE, stdin=PIPE, stderr=STDOUT)\n",
    "\ttext = p.communicate(input=string.encode('utf-8'))[0]\n",
    "\ttext = text.decode('utf-8')\n",
    "\treturn text\n",
    "\n",
    "def get_success_msg(string):\n",
    "\t'''Parses text from DataCamp `sct` JSON and returns the success message as a string.'''\n",
    "\tmatch = re.search(r'success_msg\\(\"(.*?)\"\\)', string)\n",
    "\tif match != None:\n",
    "\t\tmessage = match.group(1)\n",
    "\t\treturn message\n",
    "\telse:\n",
    "\t\treturn ''\n",
    "\n",
    "def get_correct_mc(string):\n",
    "\t'''Parses text from DataCamp `sct` JSON and correct answer for MultipleChoice type lessons. \n",
    "    Works with MultipleChoiceExercise_print'''\n",
    "\tmatch = re.search(r'test_mc\\(correct = (\\d),', string)\n",
    "\tif match != None:\n",
    "\t\tmessage = match.group(1)\n",
    "\t\treturn message\n",
    "\telse:\n",
    "\t\treturn ''\n",
    "\n",
    "def download_chapter_slides(lesson_json, filename):\n",
    "\t'''Receives lesson_json and filename from make_chapter_notes(). \n",
    "\tFinds link to PDF of slides for each chapter. \n",
    "\tSaves PDF with chapter's unique z_number and title.'''\n",
    "\tfor item in lesson_json['course']['chapters']:\n",
    "\t\turl = item['slides_link']\n",
    "\t\tif url == None:\n",
    "\t\t\tpass\n",
    "\t\telse:\n",
    "\t\t\turlretrieve(url, filename + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above code is loaded, all you have to do is grab the link for the course and run `get_whole_course()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link = 'https://www.datacamp.com/courses/free-introduction-to-r'\n",
    "get_whole_course(link)\n",
    "Print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as a bonus, you can use the below function to scrape a whole track. Below, I demo what it looks like to scrape the 21-course \"Data Scientist with R\" track that I'm currently working on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_whole_track(link):\n",
    "    html = urlopen(link)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    track = soup.find_all('a', attrs={'class':'course-block__link ds-snowplow-link-course-block'})\n",
    "    track_title = soup.title.text\n",
    "    courses = []\n",
    "\n",
    "    for x in track:\n",
    "        title = x.find('h4').text\n",
    "        tail = x.attrs['href']\n",
    "        url = 'https://www.datacamp.com' + tail\n",
    "        courses.append((title, url))\n",
    "    \n",
    "    track_file = '20180808104758 ' + track_title + '.txt'  \n",
    "    \n",
    "    with open(track_file, 'a') as f:\n",
    "        print('#', track_title + '\\n', file=f)\n",
    "        for course in courses:\n",
    "            z_num = get_whole_course(course[1], return_z=True)\n",
    "            course_name = '[[' + z_num + ']] ' + course[0]\n",
    "            print('*', course_name, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Action\n",
    "\n",
    "So what happens when you scrape a whole track? Let's take a look. Here's the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "get_whole_track('https://www.datacamp.com/tracks/data-scientist-with-r')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
